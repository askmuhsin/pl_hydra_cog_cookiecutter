{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd73e15-c25a-47eb-954a-765a3531c259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8dfe4-ea02-4612-b9b6-91fcdc68df93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973fa28-919f-4f16-a417-8e0551c97de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab5d0d-d3b0-443d-a0a5-0b8ef034b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10(root='data/', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94428bde-7a35-43bc-80a3-1817022883cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12937cd5-b002-4159-a431-c84d3def67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0e1aa-58be-48fb-8154-2f551fb6f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf595a-b800-4629-957a-d98a3fdade85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "class CIFAR10DataModule(LightningDataModule):\n",
    "    \"\"\"Example of LightningDataModule for MNIST dataset.\n",
    "\n",
    "    A DataModule implements 5 key methods:\n",
    "\n",
    "        def prepare_data(self):\n",
    "            # things to do on 1 GPU/TPU (not on every GPU/TPU in DDP)\n",
    "            # download data, pre-process, split, save to disk, etc...\n",
    "        def setup(self, stage):\n",
    "            # things to do on every process in DDP\n",
    "            # load data, set variables, etc...\n",
    "        def train_dataloader(self):\n",
    "            # return train dataloader\n",
    "        def val_dataloader(self):\n",
    "            # return validation dataloader\n",
    "        def test_dataloader(self):\n",
    "            # return test dataloader\n",
    "        def teardown(self):\n",
    "            # called on every process in DDP\n",
    "            # clean up after fit or test\n",
    "\n",
    "    This allows you to share a full dataset without explaining how to download,\n",
    "    split, transform and process the data.\n",
    "\n",
    "    Read the docs:\n",
    "        https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"data/\",\n",
    "        train_val_test_split: Tuple[int, int, int] = (50_000, 5_000, 5_000),\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        # data transformations\n",
    "        self.transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
    "                transforms.CenterCrop(size=(224, 224)),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(mean=(0.4850, 0.4560, 0.4060), std=(0.2290, 0.2240, 0.2250))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download data if needed.\n",
    "\n",
    "        Do not use it to assign state (self.x = y).\n",
    "        \"\"\"\n",
    "        CIFAR10(root=self.hparams.data_dir, train=True, download=True)\n",
    "        CIFAR10(root=self.hparams.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n",
    "\n",
    "        This method is called by lightning with both `trainer.fit()` and `trainer.test()`, so be\n",
    "        careful not to execute things like random split twice!\n",
    "        \"\"\"\n",
    "        # load and split datasets only if not loaded already\n",
    "        if not self.data_train and not self.data_val and not self.data_test:\n",
    "            trainset = CIFAR10(root=self.hparams.data_dir, train=True, download=True, transform=self.transforms)\n",
    "            testset = CIFAR10(root=self.hparams.data_dir, train=False, download=True, transform=self.transforms)\n",
    "            dataset = ConcatDataset(datasets=[trainset, testset])\n",
    "            self.data_train, self.data_val, self.data_test = random_split(\n",
    "                dataset=dataset,\n",
    "                lengths=self.hparams.train_val_test_split,\n",
    "                generator=torch.Generator().manual_seed(42),\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def teardown(self, stage: Optional[str] = None):\n",
    "        \"\"\"Clean up after fit or test.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Extra things to save to checkpoint.\"\"\"\n",
    "        return {}\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, Any]):\n",
    "        \"\"\"Things to do when loading checkpoint.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import hydra\n",
    "    import omegaconf\n",
    "    import pyrootutils\n",
    "\n",
    "    root = pyrootutils.setup_root(__file__, pythonpath=True)\n",
    "    cfg = omegaconf.OmegaConf.load(root / \"configs\" / \"datamodule\" / \"mnist.yaml\")\n",
    "    cfg.data_dir = str(root / \"data\")\n",
    "    _ = hydra.utils.instantiate(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd550b17-fbf0-4080-b670-ac54e663466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_ldm = CIFAR10DataModule()\n",
    "\n",
    "cifar10_ldm.transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
    "        transforms.CenterCrop(size=(224, 224)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=(0.4850, 0.4560, 0.4060), std=(0.2290, 0.2240, 0.2250))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6a6b5-7e7e-4ab6-8479-d497ad828671",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_ldm.prepare_data()\n",
    "cifar10_ldm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be0ce1-01ac-4078-9735-4036db2ec032",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = cifar10_ldm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7348201-bc7b-4501-b3a9-09e8b7d8d530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img, label in test_data:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337dffc-85df-44b7-9891-60758f18d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8541a-554f-4c80-bbca-27dff4c388b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de595d91-1be1-47de-84a8-5f2371a77235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    img[0].permute(1, 2, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15cbb0-c30c-4de7-b1d8-326c8190618f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timm_tester]",
   "language": "python",
   "name": "conda-env-timm_tester-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
